{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:57:41.249265Z",
     "end_time": "2023-05-04T21:57:41.249793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/sumeet/diffusion_models'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "project_root = os.path.join(str(Path.home()), 'diffusion_models')\n",
    "os.chdir(project_root)\n",
    "%pwd # should be PPGA root dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sumeet/miniconda3/envs/diffusion/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/home/sumeet/miniconda3/envs/diffusion/lib/python3.9/site-packages/trimesh/curvature.py:12: DeprecationWarning: Please use `coo_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.coo` namespace is deprecated.\n",
      "  from scipy.sparse.coo import coo_matrix\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from diffusion.gaussian_diffusion import cosine_beta_schedule, linear_beta_schedule, GaussianDiffusion\n",
    "from diffusion.latent_diffusion import LatentDiffusion\n",
    "from diffusion.ddim import DDIMSampler\n",
    "from autoencoders.policy.hypernet import HypernetAutoEncoder as AutoEncoder\n",
    "from dataset.shaped_elites_dataset import WeightNormalizer\n",
    "from attrdict import AttrDict\n",
    "from utils.tensor_dict import TensorDict, cat_tensordicts\n",
    "from RL.actor_critic import Actor\n",
    "from utils.normalize import ObsNormalizer\n",
    "from models.cond_unet import ConditionalUNet\n",
    "from envs.brax_custom.brax_env import make_vec_env_brax\n",
    "from IPython.display import HTML, Image\n",
    "from IPython.display import display\n",
    "from brax.io import html, image\n",
    "from utils.brax_utils import shared_params, rollout_many_agents"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:57:41.249408Z",
     "end_time": "2023-05-04T21:57:43.313110Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# params to config\n",
    "device = torch.device('cuda')\n",
    "env_name = 'humanoid'\n",
    "seed = 1111\n",
    "normalize_obs = True\n",
    "normalize_rewards = False\n",
    "obs_shape = shared_params[env_name]['obs_dim']\n",
    "action_shape = np.array([shared_params[env_name]['action_dim']])\n",
    "mlp_shape = (128, 128, action_shape)\n",
    "\n",
    "env_cfg = AttrDict({\n",
    "    'env_name': env_name,\n",
    "    'env_batch_size': None,\n",
    "    'num_dims': 2,\n",
    "    'seed': seed,\n",
    "    'num_envs': 1,\n",
    "    'clip_obs_rew': True,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:57:43.314778Z",
     "end_time": "2023-05-04T21:57:43.316330Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:evotorch:The logger is already configured. The default configuration will not be applied. Call `set_default_logger_config` with `override=True` to override the current configuration.\n"
     ]
    }
   ],
   "source": [
    "archive_df_path = f'data/{env_name}/archive_100x100.pkl'\n",
    "with open(archive_df_path, 'rb') as f:\n",
    "    archive_df = pickle.load(f)\n",
    "\n",
    "scheduler_path = f'data/{env_name}/scheduler_100x100.pkl'\n",
    "with open(scheduler_path, 'rb') as f:\n",
    "    scheduler = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:57:43.316956Z",
     "end_time": "2023-05-04T21:57:51.627640Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 21:57:51.812895: W external/org_tensorflow/tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:497] The NVIDIA driver's CUDA version is 11.8 which is older than the ptxas CUDA version (12.0.76). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "# make the env\n",
    "env = make_vec_env_brax(env_cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:57:51.634667Z",
     "end_time": "2023-05-04T21:57:51.954561Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def enjoy_brax(agent, render=True, deterministic=True):\n",
    "    if normalize_obs:\n",
    "        obs_mean, obs_var = agent.obs_normalizer.obs_rms.mean, agent.obs_normalizer.obs_rms.var\n",
    "        print(f'Normalize Obs Enabled')\n",
    "\n",
    "    obs = env.reset()\n",
    "    rollout = [env.unwrapped._state]\n",
    "    total_reward = 0\n",
    "    measures = torch.zeros(env_cfg.num_dims).to(device)\n",
    "    done = False\n",
    "    while not done:\n",
    "        with torch.no_grad():\n",
    "            obs = obs.unsqueeze(dim=0).to(device)\n",
    "            if normalize_obs:\n",
    "                obs = (obs - obs_mean) / torch.sqrt(obs_var + 1e-8)\n",
    "\n",
    "            if deterministic:\n",
    "                act = agent.actor_mean(obs)\n",
    "            else:\n",
    "                act, _, _ = agent.get_action(obs)\n",
    "            act = act.squeeze()\n",
    "            obs, rew, done, info = env.step(act.cpu())\n",
    "            measures += info['measures']\n",
    "            rollout.append(env.unwrapped._state)\n",
    "            total_reward += rew\n",
    "    if render:\n",
    "        i = HTML(html.render(env.unwrapped._env.sys, [s.qp for s in rollout]))\n",
    "        display(i)\n",
    "    print(f'{total_reward=}')\n",
    "    print(f' Rollout length: {len(rollout)}')\n",
    "    measures /= len(rollout)\n",
    "    print(f'Measures: {measures.cpu().numpy()}')\n",
    "    return total_reward.detach().cpu(), measures.detach().cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:57:51.957074Z",
     "end_time": "2023-05-04T21:57:51.958509Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# diffusion model params\n",
    "latent_diffusion = True\n",
    "use_ddim = True\n",
    "center_data = True\n",
    "latent_channels = 4\n",
    "latent_size = 4\n",
    "timesteps = 600\n",
    "\n",
    "cfg_path = 'results/humanoid/diffusion_model/humanoid_diffusion_model_paper_111/humanoid_diffusion_model_20230504-041644_111/args.json'\n",
    "with open(cfg_path, 'r') as f:\n",
    "    cfg = json.load(f)\n",
    "    cfg = AttrDict(cfg)\n",
    "\n",
    "scale_factor = cfg.scale_factor if latent_diffusion else None\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "betas = cosine_beta_schedule(timesteps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:57:51.959051Z",
     "end_time": "2023-05-04T21:57:52.004362Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# paths to VAE and diffusion model checkpoint\n",
    "autoencoder_path = 'results/humanoid/autoencoder/humanoid_autoencoder_paper_111/model_checkpoints/humanoid_autoencoder_20230502-081156_111.pt'\n",
    "model_path = 'results/humanoid/diffusion_model/humanoid_diffusion_model_paper_111/humanoid_diffusion_model_20230504-041644_111/model_checkpoints/humanoid_diffusion_model_20230504-041644_111.pt'\n",
    "weight_normalizer_path = 'results/humanoid/weight_normalizer.pkl'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:57:52.004777Z",
     "end_time": "2023-05-04T21:57:52.006514Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of z is: 64\n"
     ]
    }
   ],
   "source": [
    "# load the diffusion model\n",
    "logvar = torch.full(fill_value=0., size=(timesteps,))\n",
    "model = ConditionalUNet(\n",
    "    in_channels=latent_channels,\n",
    "    out_channels=latent_channels,\n",
    "    channels=64,\n",
    "    n_res_blocks=1,\n",
    "    attention_levels=[],\n",
    "    channel_multipliers=[1, 2, 4],\n",
    "    n_heads=4,\n",
    "    d_cond=256,\n",
    "    logvar=logvar\n",
    ")\n",
    "autoencoder = AutoEncoder(emb_channels=4,\n",
    "                          z_channels=4,\n",
    "                          obs_shape=obs_shape,\n",
    "                          action_shape=action_shape,\n",
    "                          z_height=4,\n",
    "                          enc_fc_hid=64,\n",
    "                          obsnorm_hid=64,\n",
    "                          ghn_hid=8)\n",
    "autoencoder.load_state_dict(torch.load(autoencoder_path))\n",
    "autoencoder.to(device)\n",
    "autoencoder.eval()\n",
    "\n",
    "gauss_diff = LatentDiffusion(betas, num_timesteps=timesteps, device=device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "\n",
    "weight_normalizer = None\n",
    "if center_data:\n",
    "    weight_normalizer = WeightNormalizer(TensorDict({}), TensorDict({}))\n",
    "    weight_normalizer.load(weight_normalizer_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:57:52.008937Z",
     "end_time": "2023-05-04T21:57:52.174436Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def postprocess_agents(rec_agents: list[Actor], obsnorms: list[dict]):\n",
    "    '''Denormalize outputs of the decoder and return a list of Actors that can be rolled out'''\n",
    "    batch_size = len(rec_agents)\n",
    "    TensorDict(obsnorms)\n",
    "    rec_agents_params = [TensorDict(p.state_dict()) for p in rec_agents]\n",
    "    rec_agents_params = cat_tensordicts(rec_agents_params)\n",
    "    rec_agents_params.update(obsnorms)\n",
    "    # decoder doesn't fill in the logstd param, so we manually set it to default values\n",
    "    actor_logstd = torch.zeros(batch_size, 1, action_shape[0])\n",
    "    actor_logstd = actor_logstd.to(device)\n",
    "    rec_agents_params['actor_logstd'] = actor_logstd\n",
    "    # if data centering was used during training, we need to denormalize the weights\n",
    "    if center_data:\n",
    "        rec_agents_params = weight_normalizer.denormalize(rec_agents_params)\n",
    "\n",
    "    if normalize_obs:\n",
    "        rec_agents_params['obs_normalizer.obs_rms.var'] = torch.exp(rec_agents_params['obs_normalizer.obs_rms.logstd'] * 2)\n",
    "        rec_agents_params['obs_normalizer.obs_rms.count'] = torch.zeros(batch_size, 1).to(device)\n",
    "        del rec_agents_params['obs_normalizer.obs_rms.logstd']\n",
    "\n",
    "    rec_agents = [Actor(obs_shape, action_shape, normalize_obs=normalize_obs).to(device) for _ in range(len(rec_agents_params))]\n",
    "    for i in range(len(rec_agents_params)):\n",
    "        rec_agents[i].load_state_dict(rec_agents_params[i])\n",
    "\n",
    "    return rec_agents"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:57:52.174537Z",
     "end_time": "2023-05-04T21:57:52.217150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "ddim_sampler = DDIMSampler(gauss_diff, n_steps=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:57:52.217107Z",
     "end_time": "2023-05-04T21:57:52.217302Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def get_agent_with_measure(m):\n",
    "    batch_size = 1\n",
    "    if isinstance(m, list):\n",
    "        cond = torch.Tensor(m).view(1, -1).to(device)\n",
    "    elif isinstance(m, torch.Tensor):\n",
    "        cond = m.view(1, -1).to(device)\n",
    "\n",
    "    shape = [batch_size, latent_channels, latent_size, latent_size]\n",
    "    samples = ddim_sampler.sample(model, shape=shape, cond=cond, classifier_free_guidance=True, classifier_scale=1.0)\n",
    "    samples = samples * (1 / scale_factor)\n",
    "    (rec_agents, obsnorms) = autoencoder.decode(samples)\n",
    "    rec_agents = postprocess_agents(rec_agents, obsnorms)\n",
    "    return rec_agents[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T22:09:18.312707Z",
     "end_time": "2023-05-04T22:09:18.364170Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "cond = torch.ones((batch_size, 2)) * 0.2\n",
    "cond = cond.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:57:52.217290Z",
     "end_time": "2023-05-04T21:57:52.261329Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shape = [batch_size, latent_channels, latent_size, latent_size]\n",
    "samples = ddim_sampler.sample(model, shape=shape, cond=cond, classifier_free_guidance=True, classifier_scale=2.0)\n",
    "samples = samples * (1 / scale_factor)\n",
    "(rec_agents, obsnorms) = autoencoder.decode(samples)\n",
    "rec_agents = postprocess_agents(rec_agents, obsnorms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T14:24:43.039525Z",
     "end_time": "2023-05-04T14:24:44.388896Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# random_idx = torch.randint(0, batch_size, (1,))\n",
    "# print(f'{random_idx=}')\n",
    "# print(len(obsnorms))\n",
    "# rec_agent = rec_agents[random_idx]\n",
    "rec_agent = get_agent_with_measure([0.5, 0.5])\n",
    "enjoy_brax(rec_agent)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T12:58:26.026334Z",
     "end_time": "2023-05-04T12:58:27.485018Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# evaluate an agent on many envs in parallel\n",
    "N = 50\n",
    "multi_env_cfg = AttrDict({\n",
    "    'env_name': env_name,\n",
    "    'env_batch_size': N,\n",
    "    'num_envs': N,\n",
    "    'num_dims': 2,\n",
    "    'seed': seed,\n",
    "    'clip_obs_rew': True,\n",
    "})\n",
    "multi_vec_env = make_vec_env_brax(multi_env_cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T21:58:56.137311Z",
     "end_time": "2023-05-04T21:58:56.197483Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rollout_many_agents([rec_agent], multi_env_cfg, multi_vec_env, device, verbose=True, normalize_obs=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T12:16:34.349919Z",
     "end_time": "2023-05-04T12:16:50.568340Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def compose_behaviors(measures, env, device, num_envs: int = 1, deterministic: bool = True, render: bool = True):\n",
    "    if num_envs > 1:\n",
    "        render = False\n",
    "    num_chunks = len(measures)\n",
    "    agents = []\n",
    "    for m in measures:\n",
    "        agent = get_agent_with_measure(m)\n",
    "        agents.append(agent)\n",
    "\n",
    "    # https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length\n",
    "    def split(a, n):\n",
    "        k, m = divmod(len(a), n)\n",
    "        return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))\n",
    "\n",
    "    time_intervals = list(split(np.arange(0, 1000), num_chunks))\n",
    "\n",
    "    num_steps = 1000\n",
    "    total_reward = torch.zeros(env.num_envs)\n",
    "    dones = torch.BoolTensor([False for _ in range(env.num_envs)]).to(device)\n",
    "    all_dones = torch.zeros((num_steps, env.num_envs)).to(device)\n",
    "    # get the per-chunk measures independent of other chunks\n",
    "    measure_data = [[] for _ in range(num_chunks)]\n",
    "\n",
    "    obs = env.reset()\n",
    "    rollout = [env.unwrapped._state]\n",
    "\n",
    "    t = 0\n",
    "    while not torch.all(dones):\n",
    "        interval_idx = next((i for i, interval in enumerate(time_intervals) if t in interval), None)\n",
    "        agent = agents[interval_idx]\n",
    "        obs_mean, obs_var = agent.obs_normalizer.obs_rms.mean, agent.obs_normalizer.obs_rms.var\n",
    "\n",
    "        obs = (obs - obs_mean) / torch.sqrt(obs_var + 1e-8)\n",
    "\n",
    "        if deterministic:\n",
    "                act = agent.actor_mean(obs)\n",
    "        else:\n",
    "            act, _, _ = agent.get_action(obs)\n",
    "        act = act.squeeze()\n",
    "        obs, rew, next_dones, info = env.step(act.cpu())\n",
    "        measure_t = info['measures'].mean(0)\n",
    "        measure_data[interval_idx].append(measure_t.detach().cpu().numpy())\n",
    "        if num_envs == 1:\n",
    "            rollout.append(env.unwrapped._state)\n",
    "        total_reward += rew.detach().cpu().numpy() * ~dones.cpu().numpy()\n",
    "        dones = torch.logical_or(dones, next_dones)\n",
    "        all_dones[t] = dones.long().clone()\n",
    "        t += 1\n",
    "    if render:\n",
    "        i = HTML(html.render(env.unwrapped._env.sys, [s.qp for s in rollout]))\n",
    "        display(i)\n",
    "\n",
    "    # the first done in each env is where that trajectory ends\n",
    "    traj_lengths = torch.argmax(all_dones, dim=0) + 1\n",
    "\n",
    "    print(f'Total Reward: {total_reward.mean().item()}, Average Trajectory Length: {traj_lengths.float().mean().item()}')\n",
    "    return measure_data, total_reward.mean().item(), traj_lengths.float().mean().item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T22:21:50.531548Z",
     "end_time": "2023-05-04T22:21:50.533321Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward.mean().item()=9220.2490234375, Average Trajectory Length: 992.1599731445312\n"
     ]
    }
   ],
   "source": [
    "measures = [\n",
    "    [0.9, 0.9],\n",
    "    [0.2, 0.2],\n",
    "    [0.5, 0.0],\n",
    "    [0.0, 0.5]\n",
    "]\n",
    "measure_data = compose_behaviors(measures, multi_vec_env, device, multi_env_cfg.num_envs, render=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T22:06:55.799011Z",
     "end_time": "2023-05-04T22:07:00.372532Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get the avg measure for each time interval independent of the other ones. Sanity check\n",
    "interval_measures = []\n",
    "for ms in measure_data:\n",
    "    ms = np.mean(np.array(ms), axis=0)\n",
    "    interval_measures.append(ms)\n",
    "print(f'{interval_measures=}')\n",
    "\n",
    "# get the moving average measures\n",
    "window_size = 50\n",
    "moving_averages = []\n",
    "all_measure_data = np.concatenate(measure_data)\n",
    "t = 0\n",
    "while t < len(all_measure_data) - window_size + 1:\n",
    "    window_average = np.sum(all_measure_data[t: t + window_size], axis=0) / window_size\n",
    "    moving_averages.append(window_average)\n",
    "    t += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T14:40:02.961437Z",
     "end_time": "2023-05-04T14:40:03.003431Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0, len(moving_averages)), [moving_averages[i][0] for i in range(len(moving_averages))])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T14:40:03.590822Z",
     "end_time": "2023-05-04T14:40:03.640892Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 6))\n",
    "ax1.plot(np.arange(0, len(moving_averages)), [moving_averages[i][0] for i in range(len(moving_averages))])\n",
    "ax2.plot(np.arange(0, len(moving_averages)), [moving_averages[i][1] for i in range(len(moving_averages))])\n",
    "ax1.set_ylabel('Measure 0')\n",
    "ax2.set_ylabel('Measure 1')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T14:43:12.297019Z",
     "end_time": "2023-05-04T14:43:12.382787Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "measures = [\n",
    "    [0.9, 0.9],\n",
    "    [0.2, 0.2],\n",
    "    [0.5, 0.0],\n",
    "    [0.0, 0.5]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def behavior_composition_experiments(N: int = 20):\n",
    "    '''Run N behavior composition experiments and report the results'''\n",
    "    avg_rewards, avg_traj_lengths = [], []\n",
    "    for n in range(N):\n",
    "        measures = torch.rand((4, 2))\n",
    "        print(f'Measures: {measures}')\n",
    "        _, avg_rew, avg_traj_len = compose_behaviors(measures, multi_vec_env, device, multi_env_cfg.num_envs)\n",
    "        avg_rewards.append(avg_rew),\n",
    "        avg_traj_lengths.append(avg_traj_len)\n",
    "        print(f'Completed trial {n + 1} of {N}')\n",
    "    successes = [1 if x > 800 else 0 for x in avg_traj_lengths]\n",
    "    success_rate = np.mean(successes)\n",
    "    print(avg_rewards)\n",
    "    print(avg_traj_lengths)\n",
    "    print(success_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T22:20:26.141330Z",
     "end_time": "2023-05-04T22:20:26.185708Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measures: tensor([[0.1638, 0.3959],\n",
      "        [0.9446, 0.9247],\n",
      "        [0.7990, 0.8603],\n",
      "        [0.2704, 0.4863]])\n",
      "Total Reward: 9511.83203125, Average Trajectory Length: 1000.0\n",
      "Completed trial 1 of 20\n",
      "Measures: tensor([[0.1251, 0.6173],\n",
      "        [0.7633, 0.9546],\n",
      "        [0.1578, 0.5750],\n",
      "        [0.1755, 0.3034]])\n",
      "Total Reward: 2619.381591796875, Average Trajectory Length: 339.1199951171875\n",
      "Completed trial 2 of 20\n",
      "Measures: tensor([[0.8514, 0.9849],\n",
      "        [0.7365, 0.4022],\n",
      "        [0.3731, 0.7758],\n",
      "        [0.4840, 0.4318]])\n",
      "Total Reward: 9298.0, Average Trajectory Length: 1000.0\n",
      "Completed trial 3 of 20\n",
      "Measures: tensor([[0.0850, 0.7936],\n",
      "        [0.7104, 0.2225],\n",
      "        [0.0060, 0.7635],\n",
      "        [0.9691, 0.7032]])\n",
      "Total Reward: 328.1335144042969, Average Trajectory Length: 69.47999572753906\n",
      "Completed trial 4 of 20\n",
      "Measures: tensor([[0.9371, 0.5870],\n",
      "        [0.3931, 0.8390],\n",
      "        [0.7796, 0.9356],\n",
      "        [0.4860, 0.6034]])\n",
      "Total Reward: 5202.2294921875, Average Trajectory Length: 595.6199951171875\n",
      "Completed trial 5 of 20\n",
      "Measures: tensor([[0.1113, 0.3932],\n",
      "        [0.0766, 0.6746],\n",
      "        [0.4810, 0.9794],\n",
      "        [0.5098, 0.9072]])\n",
      "Total Reward: 5270.021484375, Average Trajectory Length: 630.5399780273438\n",
      "Completed trial 6 of 20\n",
      "Measures: tensor([[0.4486, 0.1972],\n",
      "        [0.6638, 0.2570],\n",
      "        [0.2789, 0.9895],\n",
      "        [0.7683, 0.3968]])\n",
      "Total Reward: 9550.5478515625, Average Trajectory Length: 1000.0\n",
      "Completed trial 7 of 20\n",
      "Measures: tensor([[0.2571, 0.6439],\n",
      "        [0.5582, 0.4752],\n",
      "        [0.8085, 0.3279],\n",
      "        [0.8468, 0.9274]])\n",
      "Total Reward: 9644.169921875, Average Trajectory Length: 1000.0\n",
      "Completed trial 8 of 20\n",
      "Measures: tensor([[0.2244, 0.1513],\n",
      "        [0.8124, 0.3128],\n",
      "        [0.6172, 0.4678],\n",
      "        [0.4319, 0.0143]])\n",
      "Total Reward: 9109.1015625, Average Trajectory Length: 945.3800048828125\n",
      "Completed trial 9 of 20\n",
      "Measures: tensor([[0.2197, 0.2340],\n",
      "        [0.6084, 0.9599],\n",
      "        [0.6275, 0.1847],\n",
      "        [0.9793, 0.0605]])\n",
      "Total Reward: 5383.18701171875, Average Trajectory Length: 611.3399658203125\n",
      "Completed trial 10 of 20\n",
      "Measures: tensor([[0.8311, 0.2663],\n",
      "        [0.6490, 0.7919],\n",
      "        [0.8548, 0.6569],\n",
      "        [0.4759, 0.4444]])\n",
      "Total Reward: 6141.9267578125, Average Trajectory Length: 731.1799926757812\n",
      "Completed trial 11 of 20\n",
      "Measures: tensor([[0.3044, 0.7074],\n",
      "        [0.8237, 0.2320],\n",
      "        [0.2192, 0.0753],\n",
      "        [0.6514, 0.2128]])\n",
      "Total Reward: 8443.16015625, Average Trajectory Length: 890.5199584960938\n",
      "Completed trial 12 of 20\n",
      "Measures: tensor([[0.4769, 0.8877],\n",
      "        [0.2524, 0.1083],\n",
      "        [0.6733, 0.3366],\n",
      "        [0.3545, 0.8464]])\n",
      "Total Reward: 4163.1689453125, Average Trajectory Length: 554.0\n",
      "Completed trial 13 of 20\n",
      "Measures: tensor([[0.1033, 0.6001],\n",
      "        [0.5140, 0.1154],\n",
      "        [0.4604, 0.3465],\n",
      "        [0.5901, 0.1229]])\n",
      "Total Reward: 8905.66796875, Average Trajectory Length: 1000.0\n",
      "Completed trial 14 of 20\n",
      "Measures: tensor([[0.6724, 0.6486],\n",
      "        [0.3188, 0.6972],\n",
      "        [0.3228, 0.2180],\n",
      "        [0.3694, 0.2483]])\n",
      "Total Reward: 9496.41796875, Average Trajectory Length: 1000.0\n",
      "Completed trial 15 of 20\n",
      "Measures: tensor([[0.6325, 0.8020],\n",
      "        [0.7506, 0.8171],\n",
      "        [0.5664, 0.6828],\n",
      "        [0.5248, 0.4279]])\n",
      "Total Reward: 2277.3173828125, Average Trajectory Length: 345.6199951171875\n",
      "Completed trial 16 of 20\n",
      "Measures: tensor([[0.3158, 0.1121],\n",
      "        [0.5487, 0.3498],\n",
      "        [0.5997, 0.4591],\n",
      "        [0.0356, 0.4197]])\n",
      "Total Reward: 1416.5908203125, Average Trajectory Length: 173.0800018310547\n",
      "Completed trial 17 of 20\n",
      "Measures: tensor([[0.4422, 0.0371],\n",
      "        [0.9255, 0.3914],\n",
      "        [0.2765, 0.0928],\n",
      "        [0.4642, 0.4612]])\n",
      "Total Reward: 9447.1328125, Average Trajectory Length: 982.2999877929688\n",
      "Completed trial 18 of 20\n",
      "Measures: tensor([[0.9736, 0.0094],\n",
      "        [0.9145, 0.0215],\n",
      "        [0.4289, 0.9530],\n",
      "        [0.4682, 0.8236]])\n",
      "Total Reward: 7201.181640625, Average Trajectory Length: 832.8800048828125\n",
      "Completed trial 19 of 20\n",
      "Measures: tensor([[0.4258, 0.7293],\n",
      "        [0.7555, 0.5994],\n",
      "        [0.0714, 0.1649],\n",
      "        [0.2866, 0.1240]])\n",
      "Total Reward: 7460.96728515625, Average Trajectory Length: 793.8800048828125\n",
      "Completed trial 20 of 20\n",
      "[9511.83203125, 2619.381591796875, 9298.0, 328.1335144042969, 5202.2294921875, 5270.021484375, 9550.5478515625, 9644.169921875, 9109.1015625, 5383.18701171875, 6141.9267578125, 8443.16015625, 4163.1689453125, 8905.66796875, 9496.41796875, 2277.3173828125, 1416.5908203125, 9447.1328125, 7201.181640625, 7460.96728515625]\n",
      "[1000.0, 339.1199951171875, 1000.0, 69.47999572753906, 595.6199951171875, 630.5399780273438, 1000.0, 1000.0, 945.3800048828125, 611.3399658203125, 731.1799926757812, 890.5199584960938, 554.0, 1000.0, 1000.0, 345.6199951171875, 173.0800018310547, 982.2999877929688, 832.8800048828125, 793.8800048828125]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "behavior_composition_experiments()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T22:37:39.567674Z",
     "end_time": "2023-05-04T22:38:57.876510Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
