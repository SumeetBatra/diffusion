{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/shashank/research/qd/diffusion_models'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "project_root = os.path.join(str(Path.home()), 'research/qd/diffusion_models')\n",
    "os.chdir(project_root)\n",
    "%pwd # should be PPGA root dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoders.policy_hyperautoencoder import HyperAutoEncoder\n",
    "from envs.brax_custom.brax_env import make_vec_env_brax\n",
    "\n",
    "from dataset.policy_dataset import e_data_loader_test, env_cfg, actor_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.policy_dataset import actor_cfg, Actor, test_elites, scheduler\n",
    "import torch\n",
    "from IPython.display import HTML, Image\n",
    "from brax.io import html, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_vec_env_brax(env_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HyperAutoEncoder(\n",
       "  (encoder): ModelEncoder(\n",
       "    (dummy_actor): Actor(\n",
       "      (obs_normalizer): NormalizeObservation(\n",
       "        (obs_rms): RunningMeanStd()\n",
       "      )\n",
       "      (reward_normalizer): NormalizeReward(\n",
       "        (return_rms): RunningMeanStd()\n",
       "      )\n",
       "      (actor_mean): Sequential(\n",
       "        (0): Linear(in_features=18, out_features=128, bias=True)\n",
       "        (1): Tanh()\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (3): Tanh()\n",
       "        (4): Linear(in_features=128, out_features=6, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (out): Linear(in_features=4608, out_features=128, bias=True)\n",
       "  )\n",
       "  (decoder): MLP_GHN(\n",
       "    (ln): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "    (embed): Embedding(3, 16)\n",
       "    (shape_enc3): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (measure_enc): Linear(in_features=64, out_features=7, bias=True)\n",
       "    (gnn): GatedGNN(\n",
       "      (mlp): MLP(\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(16, 16)\n",
       "    )\n",
       "    (decoder): ConvDecoder(\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 65536, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Identity()\n",
       "      )\n",
       "      (class_layer_predictor): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (decoder_1d): MLP(\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=32, out_features=512, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (bias_class): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Linear(in_features=256, out_features=12, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (quant_conv): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (post_quant_conv): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HyperAutoEncoder(actor_cfg, emb_channels=8, z_channels=4)\n",
    "model_cp = './checkpoints/autoencoder.pt'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.load_state_dict(torch.load(model_cp))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enjoy_brax(agent, render=True, deterministic=True):\n",
    "    if actor_cfg.normalize_obs:\n",
    "        obs_mean, obs_var = agent.obs_normalizer.obs_rms.mean, agent.obs_normalizer.obs_rms.var\n",
    "\n",
    "    obs = env.reset()\n",
    "    rollout = [env.unwrapped._state]\n",
    "    total_reward = 0\n",
    "    measures = torch.zeros(env_cfg.num_dims).to(device)\n",
    "    done = False\n",
    "    while not done:\n",
    "        with torch.no_grad():\n",
    "            obs = obs.unsqueeze(dim=0).to(device)\n",
    "            if actor_cfg.normalize_obs:\n",
    "                obs = (obs - obs_mean) / torch.sqrt(obs_var + 1e-8)\n",
    "\n",
    "            if deterministic:\n",
    "                act = agent.actor_mean(obs)\n",
    "            else:\n",
    "                act, _, _ = agent.get_action(obs)\n",
    "            act = act.squeeze()\n",
    "            obs, rew, done, info = env.step(act.cpu())\n",
    "            measures += info['measures']\n",
    "            rollout.append(env.unwrapped._state)\n",
    "            total_reward += rew\n",
    "    if render:\n",
    "        i = HTML(html.render(env.unwrapped._env.sys, [s.qp for s in rollout]))\n",
    "        display(i)\n",
    "    print(f'{total_reward=}')\n",
    "    # print(f' Rollout length: {len(rollout)}')\n",
    "    measures /= len(rollout)\n",
    "    print(f'Recorded Measures: {measures.cpu().numpy()}')\n",
    "    return total_reward.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Actor(actor_cfg, obs_shape=actor_cfg.obs_shape[0], action_shape=actor_cfg.action_shape, deterministic=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_elite():\n",
    "    elite = scheduler.archive.sample_elites(1)\n",
    "    agent = Actor(actor_cfg, obs_shape=actor_cfg.obs_shape[0], action_shape=actor_cfg.action_shape).deserialize(elite.solution_batch.flatten()).to(device)\n",
    "    if actor_cfg.normalize_obs:\n",
    "        agent.obs_normalizer = elite.metadata_batch[0]['obs_normalizer']\n",
    "    return agent, elite.measures_batch[0], elite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled measure from elite: [0.98016679 0.94916666]\n"
     ]
    }
   ],
   "source": [
    "agent, measure, elite = get_random_elite()\n",
    "print(f'Sampled measure from elite: {measure}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded Measures: [0.97002995 0.97402596]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(1105.4646, dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enjoy_brax(agent, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_dict = agent.get_deserialized_weights(elite.solution_batch.flatten())\n",
    "x,y = e_data_loader_test.__iter__().__next__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_models = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desired measure: tensor([0.6312, 0.2800], device='cuda:0')\n",
      "total_reward=tensor(-433.5556, device='cuda:0')\n",
      "Recorded Measures: [0.24975024 0.18681318]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.0830, 0.7422], device='cuda:0')\n",
      "total_reward=tensor(278.1645, device='cuda:0')\n",
      "Recorded Measures: [0.03796204 0.16983016]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.6202, 0.2725], device='cuda:0')\n",
      "total_reward=tensor(-58.8245, device='cuda:0')\n",
      "Recorded Measures: [0.02797203 0.1958042 ]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.5358, 0.0772], device='cuda:0')\n",
      "total_reward=tensor(350.6901, device='cuda:0')\n",
      "Recorded Measures: [0.1038961  0.16483516]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.7707, 0.5513], device='cuda:0')\n",
      "total_reward=tensor(147.8383, device='cuda:0')\n",
      "Recorded Measures: [0.17882118 0.17982018]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.1203, 0.2340], device='cuda:0')\n",
      "total_reward=tensor(-156.8066, device='cuda:0')\n",
      "Recorded Measures: [0.05394605 0.15384614]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.3640, 0.4350], device='cuda:0')\n",
      "total_reward=tensor(187.0498, device='cuda:0')\n",
      "Recorded Measures: [0.26673326 0.21378621]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.3823, 0.8240], device='cuda:0')\n",
      "total_reward=tensor(164.7045, device='cuda:0')\n",
      "Recorded Measures: [0.15584415 0.16483516]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.1640, 0.0743], device='cuda:0')\n",
      "total_reward=tensor(-88.4464, device='cuda:0')\n",
      "Recorded Measures: [0.02697303 0.18081917]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.2773, 0.1372], device='cuda:0')\n",
      "total_reward=tensor(-27.4602, device='cuda:0')\n",
      "Recorded Measures: [0.06793207 0.2087912 ]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.0420, 0.8133], device='cuda:0')\n",
      "total_reward=tensor(-132.6197, device='cuda:0')\n",
      "Recorded Measures: [0.08491508 0.16983016]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.5848, 0.9305], device='cuda:0')\n",
      "total_reward=tensor(-173.2711, device='cuda:0')\n",
      "Recorded Measures: [0.13386613 0.14085914]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.6782, 0.2275], device='cuda:0')\n",
      "total_reward=tensor(31.2297, device='cuda:0')\n",
      "Recorded Measures: [0.03396603 0.18581419]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.5150, 0.1752], device='cuda:0')\n",
      "total_reward=tensor(10.7685, device='cuda:0')\n",
      "Recorded Measures: [0.21678321 0.2017982 ]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.1085, 0.3743], device='cuda:0')\n",
      "total_reward=tensor(-71.2344, device='cuda:0')\n",
      "Recorded Measures: [0.11688311 0.17782217]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.6975, 0.7325], device='cuda:0')\n",
      "total_reward=tensor(257.1823, device='cuda:0')\n",
      "Recorded Measures: [0.12487512 0.19280718]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.3648, 0.2918], device='cuda:0')\n",
      "total_reward=tensor(43.5071, device='cuda:0')\n",
      "Recorded Measures: [0.01798202 0.12287712]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.1062, 0.4273], device='cuda:0')\n",
      "total_reward=tensor(119.3675, device='cuda:0')\n",
      "Recorded Measures: [0.07492507 0.16483516]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.3898, 0.2110], device='cuda:0')\n",
      "total_reward=tensor(389.6093, device='cuda:0')\n",
      "Recorded Measures: [0.07992008 0.17782217]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0., 0.], device='cuda:0')\n",
      "total_reward=tensor(124.0966, device='cuda:0')\n",
      "Recorded Measures: [0.987013   0.98601395]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.4827, 0.5438], device='cuda:0')\n",
      "total_reward=tensor(92.4491, device='cuda:0')\n",
      "Recorded Measures: [0.05594406 0.14785214]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.6705, 0.6867], device='cuda:0')\n",
      "total_reward=tensor(-120.4637, device='cuda:0')\n",
      "Recorded Measures: [0.1038961  0.12987013]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.0595, 0.6793], device='cuda:0')\n",
      "total_reward=tensor(79.9563, device='cuda:0')\n",
      "Recorded Measures: [0.11288711 0.1998002 ]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.4030, 0.2707], device='cuda:0')\n",
      "total_reward=tensor(-257.1032, device='cuda:0')\n",
      "Recorded Measures: [0.17582417 0.17682317]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.5413, 0.2062], device='cuda:0')\n",
      "total_reward=tensor(124.8685, device='cuda:0')\n",
      "Recorded Measures: [0.07892108 0.16383617]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.6803, 0.1175], device='cuda:0')\n",
      "total_reward=tensor(192.3179, device='cuda:0')\n",
      "Recorded Measures: [0.07692307 0.23476523]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.4012, 0.1868], device='cuda:0')\n",
      "total_reward=tensor(111.2547, device='cuda:0')\n",
      "Recorded Measures: [0.03296703 0.16583416]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0., 0.], device='cuda:0')\n",
      "total_reward=tensor(213.9264, device='cuda:0')\n",
      "Recorded Measures: [0.99000996 0.994006  ]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0., 0.], device='cuda:0')\n",
      "total_reward=tensor(157.1383, device='cuda:0')\n",
      "Recorded Measures: [0.9800199  0.99300694]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.6698, 0.2183], device='cuda:0')\n",
      "total_reward=tensor(-148.2900, device='cuda:0')\n",
      "Recorded Measures: [0.02697303 0.13886113]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.7122, 0.9492], device='cuda:0')\n",
      "total_reward=tensor(568.3060, device='cuda:0')\n",
      "Recorded Measures: [0.2987013  0.25374624]\n",
      "--------------------------------------------------------------------\n",
      "Desired measure: tensor([0.0768, 0.5028], device='cuda:0')\n",
      "total_reward=tensor(-75.6071, device='cuda:0')\n",
      "Recorded Measures: [0.04195804 0.16483516]\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, recon_model in enumerate(reconstructed_models[0]):\n",
    "    desired_measure = y[i]\n",
    "    print(f'Desired measure: {desired_measure}')\n",
    "    agent.actor_mean = recon_model\n",
    "    enjoy_brax(agent, render=False)\n",
    "    print('--------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c437a21b275005b244436c232defa84105462a85d5e3990796798eae336d0140"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
