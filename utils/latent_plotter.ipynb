{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/shashank/research/qd/main/diffusion_models'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "project_root = os.path.join('/home/shashank/research/qd/main/diffusion_models')\n",
    "os.chdir(project_root)\n",
    "%pwd # should be PPGA root dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashank/miniconda3/envs/qd/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:evotorch:The logger is already configured. The default configuration will not be applied. Call `set_default_logger_config` with `override=True` to override the current configuration.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update(\n",
    "    {\n",
    "        \"figure.dpi\": 150,\n",
    "        \"font.size\": 20,\n",
    "    }\n",
    ")\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Optional\n",
    "from diffusion.gaussian_diffusion import cosine_beta_schedule, linear_beta_schedule, GaussianDiffusion\n",
    "from diffusion.latent_diffusion import LatentDiffusion\n",
    "from diffusion.ddim import DDIMSampler\n",
    "from autoencoders.policy.hypernet import HypernetAutoEncoder as AutoEncoder\n",
    "from dataset.shaped_elites_dataset import WeightNormalizer\n",
    "from attrdict import AttrDict\n",
    "from utils.tensor_dict import TensorDict, cat_tensordicts\n",
    "from RL.actor_critic import Actor\n",
    "from utils.normalize import ObsNormalizer\n",
    "from models.cond_unet import ConditionalUNet, LangConditionalUNet\n",
    "from envs.brax_custom.brax_env import make_vec_env_brax\n",
    "from utils.brax_utils import shared_params, rollout_many_agents\n",
    "from algorithm.train_autoencoder import shaped_elites_dataset_factory\n",
    "from autoencoders.policy.hypernet import HypernetAutoEncoder, ModelEncoder\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# params to config\n",
    "device = torch.device('cuda')\n",
    "env_name = 'humanoid'\n",
    "seed = 1111\n",
    "normalize_obs = True\n",
    "normalize_rewards = False\n",
    "obs_shape = shared_params[env_name]['obs_dim']\n",
    "action_shape = np.array([shared_params[env_name]['action_dim']])\n",
    "mlp_shape = (128, 128, action_shape)\n",
    "train_batch_size=32\n",
    "latent_diffusion = True\n",
    "use_ddim = True\n",
    "center_data = True\n",
    "use_language = True\n",
    "latent_channels = 4\n",
    "latent_size = 4\n",
    "timesteps = 600\n",
    "\n",
    "\n",
    "env_cfg = AttrDict({\n",
    "    'env_name': env_name,\n",
    "    'env_batch_size': None,\n",
    "    'num_dims': 2,\n",
    "    'seed': seed,\n",
    "    'num_envs': 1,\n",
    "    'clip_obs_rew': True,\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# paths to VAE and diffusion model checkpoint\n",
    "autoencoder_path = '/home/shashank/research/qd/paper_language_results/humanoid/autoencoder/humanoid_autoencoder_20230503-072924_111/model_checkpoints/humanoid_autoencoder_20230503-072924_111.pt'\n",
    "model_path = '/home/shashank/research/qd/paper_language_results/humanoid/diffusion_model/humanoid_diffusion_model_20230515-032333_0/model_checkpoints/humanoid_diffusion_model_20230515-032333_0.pt'\n",
    "weight_normalizer_path = 'results/humanoid/weight_normalizer.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[1m[2023-05-17 04:28:56,342][16650] Loading archive at data/humanoid/archive100x100.pkl\u001b[0m\n",
      "7470it [00:19, 379.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of z is: 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HypernetAutoEncoder(\n",
       "  (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (encoder): ModelEncoder(\n",
       "    (cnns): ModuleDict(\n",
       "      (obs_normalizer_obs_rms_mean): Sequential(\n",
       "        (fc1): Linear(in_features=227, out_features=64, bias=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (obs_normalizer_obs_rms_var): Sequential(\n",
       "        (fc1): Linear(in_features=227, out_features=64, bias=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (actor_mean_0_weight): Sequential(\n",
       "        (cnn_block_0): Sequential(\n",
       "          (conv0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu0): ReLU(inplace=True)\n",
       "          (maxpool_0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_1): Sequential(\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (maxpool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_2): Sequential(\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (maxpool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_3): Sequential(\n",
       "          (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu3): ReLU(inplace=True)\n",
       "          (maxpool_3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_4): Sequential(\n",
       "          (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu4): ReLU(inplace=True)\n",
       "          (maxpool_4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_5): Sequential(\n",
       "          (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu5): ReLU(inplace=True)\n",
       "          (maxpool_5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_6): Sequential(\n",
       "          (conv6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu6): ReLU(inplace=True)\n",
       "          (maxpool_6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (actor_mean_0_bias): Sequential(\n",
       "        (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (actor_mean_2_weight): Sequential(\n",
       "        (cnn_block_0): Sequential(\n",
       "          (conv0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu0): ReLU(inplace=True)\n",
       "          (maxpool_0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_1): Sequential(\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (maxpool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_2): Sequential(\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (maxpool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_3): Sequential(\n",
       "          (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu3): ReLU(inplace=True)\n",
       "          (maxpool_3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_4): Sequential(\n",
       "          (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu4): ReLU(inplace=True)\n",
       "          (maxpool_4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_5): Sequential(\n",
       "          (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu5): ReLU(inplace=True)\n",
       "          (maxpool_5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_6): Sequential(\n",
       "          (conv6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu6): ReLU(inplace=True)\n",
       "          (maxpool_6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (actor_mean_2_bias): Sequential(\n",
       "        (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (actor_mean_4_weight): Sequential(\n",
       "        (cnn_block_0): Sequential(\n",
       "          (conv0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu0): ReLU(inplace=True)\n",
       "          (maxpool_0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_1): Sequential(\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (maxpool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_2): Sequential(\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (maxpool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (cnn_block_3): Sequential(\n",
       "          (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (batchnorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu3): ReLU(inplace=True)\n",
       "          (maxpool_3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (actor_mean_4_bias): Sequential(\n",
       "        (fc1): Linear(in_features=17, out_features=64, bias=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (out): Linear(in_features=2368, out_features=128, bias=True)\n",
       "  )\n",
       "  (decoder): MLP_GHN(\n",
       "    (embed): Embedding(3, 32)\n",
       "    (z_encoder): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (shape_enc3): Linear(in_features=1, out_features=32, bias=True)\n",
       "    (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (gnn): GatedGNN(\n",
       "      (mlp): MLP(\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (gru): GRUCell(64, 64)\n",
       "    )\n",
       "    (decoder): ConvDecoder(\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 65536, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Identity()\n",
       "      )\n",
       "      (class_layer_predictor): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Conv2d(256, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (decoder_1d): MLP(\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (bias_class): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Linear(in_features=256, out_features=34, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (obsnorm_decoder): ObsNormDecoder(\n",
       "    (mean_dec): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=227, bias=True)\n",
       "    )\n",
       "    (std_dec): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=227, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_normalizer = None\n",
    "dataloader, train_archive, weight_normalizer = shaped_elites_dataset_factory(env_name,\n",
    "                                                                                batch_size=train_batch_size,\n",
    "                                                                                is_eval=False,\n",
    "                                                                                center_data=center_data,\n",
    "                                                                                cut_out=False,\n",
    "                                                                                weight_normalizer=weight_normalizer)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = HypernetAutoEncoder(emb_channels=4,\n",
    "                            z_channels=4,\n",
    "                            obs_shape=obs_shape,\n",
    "                            action_shape=action_shape,\n",
    "                            z_height=4,\n",
    "                            conditional=False,\n",
    "                            ghn_hid=32,\n",
    "                            enc_fc_hid = 64,\n",
    "                            obsnorm_hid=64,\n",
    "                            )\n",
    "model.load_state_dict(torch.load(autoencoder_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "234it [00:16, 14.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# get the latent representation of the dataset by getting the mean of the posterior\n",
    "latent_dataset = []\n",
    "measures_0 = []\n",
    "measures_1 = []\n",
    "for step, (policies, measures) in tqdm(enumerate(dataloader)):\n",
    "    _, posterior = model(policies)\n",
    "    latent_dataset.append(posterior.mean.flatten(1).detach().cpu().numpy())\n",
    "    measures_0.append(measures[:,0].detach().cpu().numpy())\n",
    "    measures_1.append(measures[:,1].detach().cpu().numpy())\n",
    "\n",
    "latent_dataset = np.concatenate(latent_dataset, axis=0)\n",
    "measures_0 = np.concatenate(measures_0, axis=0)\n",
    "measures_1 = np.concatenate(measures_1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tsne to visualize the latent space\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=3, perplexity=5, n_jobs=-1)\n",
    "latent_dataset_tsne = tsne.fit_transform(latent_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
